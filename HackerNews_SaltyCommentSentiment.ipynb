{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01bd76ab9782c73646930a8c6ac495eb93d52786"
   },
   "source": [
    "# Hacker News Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#!pip install google-cloud-bigquery\n",
    "#!pip install textblob\n",
    "#!pip install swifter\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from textblob import TextBlob\n",
    "import bokeh\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import html \n",
    "import dask\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import swifter\n",
    "\n",
    "\n",
    "'''import swifter\n",
    "df.swifter.apply(func)'''\n",
    "\n",
    "# Define the BigQuery Client\n",
    "client = bigquery.Client.from_service_account_json(\"winterrose-nlp-49041459bd3c.json\")\n",
    "\n",
    "# A Google BigQuery Function\n",
    "def querytodf(query):\n",
    "    query_job = client.query(query)\n",
    "    \n",
    "    iterator = query_job.result(timeout=60)\n",
    "    rows = list(iterator)\n",
    "\n",
    "    # Transform the rows into a nice pandas dataframe\n",
    "    df = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Using WHERE reduces the amount of data scanned / quota used\n",
    "query = \"\"\"\n",
    "SELECT hnc.id, \n",
    "       hnc.by,\n",
    "       hnc.author,\n",
    "       hnc.text, \n",
    "       hnc.time, \n",
    "       hnc.ranking, \n",
    "       hnc.deleted, \n",
    "       hnc.dead, \n",
    "       hnc.parent as sid,\n",
    "       hns.by as sauthor,\n",
    "       hns.time as stime,\n",
    "       hns.title as stitle,\n",
    "       hns.deleted as sdeleted,\n",
    "       hns.dead as sdead,\n",
    "       hns.score as score,\n",
    "       hns.text as stext,\n",
    "       hns.url as surl\n",
    "FROM `bigquery-public-data.hacker_news.comments` as hnc\n",
    "INNER JOIN `bigquery-public-data.hacker_news.stories`as hns ON hns.id  = hnc.parent\n",
    "\"\"\"\n",
    "df = querytodf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b88e551ef1d6c2562e1beff9d60be3c88e83ce02"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6d7b7611d8aa093224b66ec3131a8586cc71b20"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas Dataframe to Dask Dataframe and then save to Disk as CSV.\n",
    "#!mkdir data\n",
    "ds = dd.from_pandas(df, npartitions=30)\n",
    "ds.to_csv('data/export-*.csv').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trash the old ones from memory. \n",
    "del ds, df\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT FROM CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# IMPORT FROM CSV's\n",
    "ds2 = dd.read_csv('data/export-*.csv').compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# IMPORT FROM CSV's\n",
    "ds2 = dd.read_csv('data/export-*.csv').compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = ds2.text.isna().sum()\n",
    "nans\n",
    "ds2 = ds2.dropna(subset=['author', 'text'])\n",
    "ds2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "800fd0be97d8d4111ebcb7c6d5968cc944bc08b7"
   },
   "outputs": [],
   "source": [
    "# Define sentiment Analysis function\n",
    "\n",
    "def encode_decode(text):\n",
    "    unescaped = html.unescape(text)\n",
    "    return unescaped\n",
    "\n",
    "def noHTML(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', text)\n",
    "    return cleantext\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed text\n",
    "    using textblob's sentiment method. Return the polarity\n",
    "    score as a float within the range [-1.0, 1.0]\n",
    "    \"\"\"\n",
    "    # create TextBlob object of passed text's polarity\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def noURLS(text):\n",
    "    \"\"\"\n",
    "    Utility function to clean text by removing links\n",
    "    using simple regex statements.\n",
    "    \"\"\"\n",
    "    return ''.join(re.sub(r\"http\\S+\", \"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_pandas(tqdm())\n",
    "# via Pandas\n",
    "ds2['cleaned_comment'] = ds2.text.progress_apply(lambda x: noURLS(noHTML(encode_decode(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# via Swifter\n",
    "ds2.text.swifter.apply(lambda x: noURLS(noHTML(encode_decode(x))))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# via Dask\n",
    "ds2.text.apply(lambda x: noURLS(noHTML(encode_decode(x)))).compute(scheduler='threads')\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2['comment_sentiment'] = ds2['cleaned_comment'].swifter.apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6 = ds2.loc[:, ~ds2.columns.str.match('Unnamed')]\n",
    "ds6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds3['comment_sentiment_dask'] = ds3['cleaned_comment'].apply(lambda x: get_sentiment(x)).compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a53f7b8378f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ds2export.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ds2' is not defined"
     ]
    }
   ],
   "source": [
    "#ds2.to_csv('data/ds2export.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 3.21 s, total: 41.6 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# IMPORT FROM CSV's\n",
    "d1 = pd.read_csv('data/ds2export.csv')\n",
    "d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = d1.loc[:, ~d1.columns.str.match('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183926"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentorList = ds3.by.unique().tolist()\n",
    "len(commentorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cList = pd.DataFrame(commentorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jpeg_hero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>josephpmay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opendomain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>darrellsilver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commentor\n",
       "0      jpeg_hero\n",
       "1          barce\n",
       "2     josephpmay\n",
       "3     opendomain\n",
       "4  darrellsilver"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cList.columns = ['commentor']\n",
    "cList.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c8a34859a7fbc3f85acb1bcaae6815a0ec09753e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.4 ms, sys: 8 ms, total: 95.4 ms\n",
      "Wall time: 94.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create testingDF for df format\n",
    "x = 'eli'\n",
    "\n",
    "# Select subdf for the selected author. \n",
    "subdf = ds3[ds3['by'].values == x]\n",
    "\n",
    "# Commentor\n",
    "commentor = x\n",
    "\n",
    "# Create the first output, a float indicating commentor's mean sentiment score. \n",
    "commentor_sentiment = subdf['comment_sentiment'].mean() \n",
    "\n",
    "# Upvotes Mean\n",
    "commentor_upvotes_mean = subdf['ranking'].mean() \n",
    "\n",
    "# Upvotes Total\n",
    "commentor_upvotes_total = subdf['ranking'].sum()\n",
    "\n",
    "# Total Happiness\n",
    "commentor_total_happyness = subdf[subdf['comment_sentiment'] > 0.0].comment_sentiment.sum() \n",
    "\n",
    "# Total Saltiness\n",
    "commentor_total_saltiness = subdf[subdf['comment_sentiment'] < 0.0].comment_sentiment.sum() \n",
    "\n",
    "# Third output, total number of commments\n",
    "total_comments = len(subdf.index)\n",
    "\n",
    "# Total salty comments\n",
    "qty_salty_comments = (subdf.comment_sentiment < 0.0).sum()\n",
    "\n",
    "# Total non-salty comments\n",
    "qty_non_salty_comments = (subdf.comment_sentiment > 0.0).sum()\n",
    "\n",
    "# Create the second output, a list of the commentor's saltiest comments. \n",
    "salty_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']][0:9].to_json(orient='records')\n",
    "\n",
    "# Ten most positive comments\n",
    "sweet_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']].tail(10).to_json(orient='records')\n",
    "\n",
    "outputDF = pd.DataFrame.from_records([{ 'commentor': commentor, \n",
    "                                        'commentor_sentiment': commentor_sentiment, \n",
    "                                        'commentor_upvotes_mean': commentor_upvotes_mean,\n",
    "                                        'commentor_upvotes_total': commentor_upvotes_total,\n",
    "                                        'commentor_total_happyness': commentor_total_happyness,\n",
    "                                        'commentor_total_saltiness': commentor_total_saltiness,\n",
    "                                        'total_comments': total_comments,\n",
    "                                        'qty_salty_comments': qty_salty_comments, \n",
    "                                        'qty_non_salty_comments': qty_non_salty_comments,\n",
    "                                        'salty_comments': salty_comments, \n",
    "                                        'sweet_comments': sweet_comments} ])\n",
    "\n",
    "testingDF = outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentor</th>\n",
       "      <th>commentor_sentiment</th>\n",
       "      <th>commentor_total_happyness</th>\n",
       "      <th>commentor_total_saltiness</th>\n",
       "      <th>commentor_upvotes_mean</th>\n",
       "      <th>commentor_upvotes_total</th>\n",
       "      <th>qty_non_salty_comments</th>\n",
       "      <th>qty_salty_comments</th>\n",
       "      <th>salty_comments</th>\n",
       "      <th>sweet_comments</th>\n",
       "      <th>total_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eli</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>147.795118</td>\n",
       "      <td>-51.737913</td>\n",
       "      <td>8.584439</td>\n",
       "      <td>9709</td>\n",
       "      <td>658</td>\n",
       "      <td>286</td>\n",
       "      <td>[{\"time\":1426095792,\"comment_sentiment\":0.0031...</td>\n",
       "      <td>[{\"time\":1307486234,\"comment_sentiment\":0.075,...</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  commentor  commentor_sentiment  commentor_total_happyness  \\\n",
       "0       eli             0.084931                 147.795118   \n",
       "\n",
       "   commentor_total_saltiness  commentor_upvotes_mean  commentor_upvotes_total  \\\n",
       "0                 -51.737913                8.584439                     9709   \n",
       "\n",
       "   qty_non_salty_comments  qty_salty_comments  \\\n",
       "0                     658                 286   \n",
       "\n",
       "                                      salty_comments  \\\n",
       "0  [{\"time\":1426095792,\"comment_sentiment\":0.0031...   \n",
       "\n",
       "                                      sweet_comments  total_comments  \n",
       "0  [{\"time\":1307486234,\"comment_sentiment\":0.075,...            1131  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(testingDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = testingDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183926"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commentorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopSum(i):  \n",
    "    # Select subdf for the selected author.\n",
    "    subdf = ds3[ds3['by'].values == i]\n",
    "    # Commentor\n",
    "    commentor = i\n",
    "    # Create the first output, a float indicating commentor's mean sentiment score. \n",
    "    commentor_sentiment = subdf['comment_sentiment'].mean() \n",
    "    # Upvotes Mean\n",
    "    commentor_upvotes_mean = subdf['ranking'].mean() \n",
    "    # Upvotes Total\n",
    "    commentor_upvotes_total = subdf['ranking'].sum()\n",
    "    # Total Happiness\n",
    "    commentor_total_happyness = subdf[subdf['comment_sentiment'] > 0.0].comment_sentiment.sum() \n",
    "    # Total Saltiness\n",
    "    commentor_total_saltiness = subdf[subdf['comment_sentiment'] < 0.0].comment_sentiment.sum() \n",
    "    # Third output, total number of commments\n",
    "    total_comments = len(subdf.index)\n",
    "    # Total salty comments\n",
    "    qty_salty_comments = (subdf.comment_sentiment < 0.0).sum()\n",
    "    # Total non-salty comments\n",
    "    qty_non_salty_comments = (subdf.comment_sentiment > 0.0).sum()\n",
    "    # Create the second output, a list of the commentor's saltiest comments. \n",
    "    salty_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']][0:9].to_json(orient='records')\n",
    "    # Ten most positive comments\n",
    "    sweet_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']].tail(10).to_json(orient='records')\n",
    "    outputDF = pd.DataFrame([{ 'commentor': commentor, \n",
    "                                            'commentor_sentiment': commentor_sentiment, \n",
    "                                            'commentor_upvotes_mean': commentor_upvotes_mean,\n",
    "                                            'commentor_upvotes_total': commentor_upvotes_total,\n",
    "                                            'commentor_total_happyness': commentor_total_happyness,\n",
    "                                            'commentor_total_saltiness': commentor_total_saltiness,\n",
    "                                            'total_comments': total_comments,\n",
    "                                            'qty_salty_comments': qty_salty_comments, \n",
    "                                            'qty_non_salty_comments': qty_non_salty_comments,\n",
    "                                            'salty_comments': salty_comments, \n",
    "                                            'sweet_comments': sweet_comments} ])\n",
    "    return outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 4410/183926 [05:23<3:34:00, 13.98it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "    \n",
    "results = []\n",
    "for j in tqdm(commentorList[0:183926]):\n",
    "    newDF = loopSum(j)\n",
    "    results.append(newDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTableResults = pd.concat(results)\n",
    "finalTableResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTableResults.to_csv('data/commentor_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTableResults.to_parquet('data/commentor_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183926, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTableResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#!pip install pandavro\n",
    "import pandavro as pdx\n",
    "\n",
    "#OUTPUT_PATH='{}/data/example.avro'.format(os.path.dirname(__file__))\n",
    "\n",
    "\n",
    "dxx = pd.DataFrame({\"Boolean\": [True, False, True, False],\n",
    "                   \"Float64\": np.random.randn(4),\n",
    "                   \"Int64\": np.random.randint(0, 10, 4),\n",
    "                   \"String\": ['foo', 'bar', 'foo', 'bar'],\n",
    "                   \"DateTime64\": [pd.Timestamp('20190101'), pd.Timestamp('20190102'),\n",
    "                                  pd.Timestamp('20190103'), pd.Timestamp('20190104')]})\n",
    "\n",
    "pdx.to_avro('data/hn_commentors_db.avro', finalTableResults)\n",
    "saved = pdx.read_avro('data/hn_commentors_db.avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentor</th>\n",
       "      <th>commentor_sentiment</th>\n",
       "      <th>commentor_total_happyness</th>\n",
       "      <th>commentor_total_saltiness</th>\n",
       "      <th>commentor_upvotes_mean</th>\n",
       "      <th>commentor_upvotes_total</th>\n",
       "      <th>qty_non_salty_comments</th>\n",
       "      <th>qty_salty_comments</th>\n",
       "      <th>salty_comments</th>\n",
       "      <th>sweet_comments</th>\n",
       "      <th>total_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jpeg_hero</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>12.108628</td>\n",
       "      <td>-7.985893</td>\n",
       "      <td>23.125000</td>\n",
       "      <td>2220</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>[{\"time\":1339013609,\"comment_sentiment\":0.0,\"r...</td>\n",
       "      <td>[{\"time\":1385394486,\"comment_sentiment\":-0.024...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barce</td>\n",
       "      <td>0.174968</td>\n",
       "      <td>14.072513</td>\n",
       "      <td>-1.649803</td>\n",
       "      <td>20.732394</td>\n",
       "      <td>1472</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>[{\"time\":1326303831,\"comment_sentiment\":0.1479...</td>\n",
       "      <td>[{\"time\":1426269657,\"comment_sentiment\":0.0,\"r...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>josephpmay</td>\n",
       "      <td>0.129768</td>\n",
       "      <td>19.228468</td>\n",
       "      <td>-4.045566</td>\n",
       "      <td>7.247863</td>\n",
       "      <td>848</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>[{\"time\":1373721992,\"comment_sentiment\":0.0,\"r...</td>\n",
       "      <td>[{\"time\":1364939435,\"comment_sentiment\":-0.152...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opendomain</td>\n",
       "      <td>0.159312</td>\n",
       "      <td>20.135372</td>\n",
       "      <td>-1.655124</td>\n",
       "      <td>8.232759</td>\n",
       "      <td>955</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>[{\"time\":1337896054,\"comment_sentiment\":0.5,\"r...</td>\n",
       "      <td>[{\"time\":1417001198,\"comment_sentiment\":0.3,\"r...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>darrellsilver</td>\n",
       "      <td>0.265126</td>\n",
       "      <td>11.086797</td>\n",
       "      <td>-0.746875</td>\n",
       "      <td>22.205128</td>\n",
       "      <td>866</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>[{\"time\":1389388135,\"comment_sentiment\":-0.063...</td>\n",
       "      <td>[{\"time\":1374354465,\"comment_sentiment\":0.2123...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nshankar</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>4.436171</td>\n",
       "      <td>-0.694683</td>\n",
       "      <td>16.413793</td>\n",
       "      <td>476</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>[{\"time\":1366261218,\"comment_sentiment\":0.15,\"...</td>\n",
       "      <td>[{\"time\":1359348181,\"comment_sentiment\":0.5,\"r...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adamrneary</td>\n",
       "      <td>0.043665</td>\n",
       "      <td>1.150998</td>\n",
       "      <td>-0.758011</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[{\"time\":1314204698,\"comment_sentiment\":0.2105...</td>\n",
       "      <td>[{\"time\":1314204698,\"comment_sentiment\":0.2105...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Daniel_Newby</td>\n",
       "      <td>0.090960</td>\n",
       "      <td>21.286754</td>\n",
       "      <td>-6.915050</td>\n",
       "      <td>11.613924</td>\n",
       "      <td>1835</td>\n",
       "      <td>94</td>\n",
       "      <td>39</td>\n",
       "      <td>[{\"time\":1262413986,\"comment_sentiment\":0.0845...</td>\n",
       "      <td>[{\"time\":1276718795,\"comment_sentiment\":-0.321...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pravin</td>\n",
       "      <td>0.278283</td>\n",
       "      <td>0.834848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"time\":1216792904,\"comment_sentiment\":0.1666...</td>\n",
       "      <td>[{\"time\":1216792904,\"comment_sentiment\":0.1666...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b05us</td>\n",
       "      <td>0.195677</td>\n",
       "      <td>1.307396</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"time\":1257962656,\"comment_sentiment\":0.1263...</td>\n",
       "      <td>[{\"time\":1257962656,\"comment_sentiment\":0.1263...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commentor  commentor_sentiment  commentor_total_happyness  \\\n",
       "0      jpeg_hero             0.042945                  12.108628   \n",
       "1          barce             0.174968                  14.072513   \n",
       "2     josephpmay             0.129768                  19.228468   \n",
       "3     opendomain             0.159312                  20.135372   \n",
       "4  darrellsilver             0.265126                  11.086797   \n",
       "5       nshankar             0.129017                   4.436171   \n",
       "6     adamrneary             0.043665                   1.150998   \n",
       "7   Daniel_Newby             0.090960                  21.286754   \n",
       "8         Pravin             0.278283                   0.834848   \n",
       "9          b05us             0.195677                   1.307396   \n",
       "\n",
       "   commentor_total_saltiness  commentor_upvotes_mean  commentor_upvotes_total  \\\n",
       "0                  -7.985893               23.125000                     2220   \n",
       "1                  -1.649803               20.732394                     1472   \n",
       "2                  -4.045566                7.247863                      848   \n",
       "3                  -1.655124                8.232759                      955   \n",
       "4                  -0.746875               22.205128                      866   \n",
       "5                  -0.694683               16.413793                      476   \n",
       "6                  -0.758011               18.555556                      167   \n",
       "7                  -6.915050               11.613924                     1835   \n",
       "8                   0.000000                1.000000                        3   \n",
       "9                  -0.133333               12.000000                       72   \n",
       "\n",
       "   qty_non_salty_comments  qty_salty_comments  \\\n",
       "0                      43                  32   \n",
       "1                      50                  13   \n",
       "2                      72                  25   \n",
       "3                      83                  16   \n",
       "4                      28                   6   \n",
       "5                      20                   5   \n",
       "6                       5                   4   \n",
       "7                      94                  39   \n",
       "8                       3                   0   \n",
       "9                       5                   1   \n",
       "\n",
       "                                      salty_comments  \\\n",
       "0  [{\"time\":1339013609,\"comment_sentiment\":0.0,\"r...   \n",
       "1  [{\"time\":1326303831,\"comment_sentiment\":0.1479...   \n",
       "2  [{\"time\":1373721992,\"comment_sentiment\":0.0,\"r...   \n",
       "3  [{\"time\":1337896054,\"comment_sentiment\":0.5,\"r...   \n",
       "4  [{\"time\":1389388135,\"comment_sentiment\":-0.063...   \n",
       "5  [{\"time\":1366261218,\"comment_sentiment\":0.15,\"...   \n",
       "6  [{\"time\":1314204698,\"comment_sentiment\":0.2105...   \n",
       "7  [{\"time\":1262413986,\"comment_sentiment\":0.0845...   \n",
       "8  [{\"time\":1216792904,\"comment_sentiment\":0.1666...   \n",
       "9  [{\"time\":1257962656,\"comment_sentiment\":0.1263...   \n",
       "\n",
       "                                      sweet_comments  total_comments  \n",
       "0  [{\"time\":1385394486,\"comment_sentiment\":-0.024...              96  \n",
       "1  [{\"time\":1426269657,\"comment_sentiment\":0.0,\"r...              71  \n",
       "2  [{\"time\":1364939435,\"comment_sentiment\":-0.152...             117  \n",
       "3  [{\"time\":1417001198,\"comment_sentiment\":0.3,\"r...             116  \n",
       "4  [{\"time\":1374354465,\"comment_sentiment\":0.2123...              39  \n",
       "5  [{\"time\":1359348181,\"comment_sentiment\":0.5,\"r...              29  \n",
       "6  [{\"time\":1314204698,\"comment_sentiment\":0.2105...               9  \n",
       "7  [{\"time\":1276718795,\"comment_sentiment\":-0.321...             158  \n",
       "8  [{\"time\":1216792904,\"comment_sentiment\":0.1666...               3  \n",
       "9  [{\"time\":1257962656,\"comment_sentiment\":0.1263...               6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(saved.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Graveyard - Ideas that didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nope\n",
    "dsr3 = ds2\n",
    "dsr3['cleaned_comment'] = dsr3.text.apply(lambda x: noURLS(noHTML(encode_decode(x)))).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER\n",
    "\n",
    "dsr3 = dd.from_pandas(ds2, npartitions=2000)\n",
    "\n",
    "finalDF = dsr2\n",
    "def fin (daskDataframe):\n",
    "    daskDataframe['comment_sentiment'] = daskDataframe.text.apply(lambda x: get_sentiment(noURLS(noHTML(encode_decode(x)))))\n",
    "    daskDataframe['cleaned_comment'] = daskDataframe.text.apply(lambda x: noURLS(noHTML(encode_decode(x))))\n",
    "    return finalDF\n",
    "\n",
    "with ProgressBar():\n",
    "    res = fin(dsr2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select subdf for the selected author. \n",
    "subdf = ds2[ds2['by'].values == x]\n",
    "\n",
    "# Commentor\n",
    "commentor = x\n",
    "\n",
    "# Create the first output, a float indicating commentor's mean sentiment score. \n",
    "commentor_sentiment = subdf['comment_sentiment'].mean() \n",
    "\n",
    "# Upvotes Mean\n",
    "commentor_upvotes_mean = subdf['ranking'].mean() \n",
    "\n",
    "# Upvotes Total\n",
    "commentor_upvotes_total = subdf['ranking'].sum()\n",
    "\n",
    "# Total Happiness\n",
    "commentor_total_happyness = subdf[subdf['comment_sentiment'] > 0.0].comment_sentiment.sum() \n",
    "\n",
    "# Total Saltiness\n",
    "commentor_total_saltiness = subdf[subdf['comment_sentiment'] < 0.0].comment_sentiment.sum() \n",
    "\n",
    "# Third output, total number of commments\n",
    "total_comments = len(subdf.index)\n",
    "\n",
    "# Total salty comments\n",
    "qty_salty_comments = (subdf.comment_sentiment < 0.0).sum()\n",
    "\n",
    "# Total non-salty comments\n",
    "qty_non_salty_comments = (subdf.comment_sentiment > 0.0).sum()\n",
    "\n",
    "# Create the second output, a list of the commentor's saltiest comments. \n",
    "salty_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']][0:9].to_json(orient='records')\n",
    "\n",
    "# Ten most positive comments\n",
    "sweet_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']].tail(10).to_json(orient='records')\n",
    "\n",
    "outputDF = pd.DataFrame.from_records([{ 'commentor': commentor, \n",
    "                                        'commentor_sentiment': commentor_sentiment, \n",
    "                                        'commentor_upvotes_mean': commentor_upvotes_mean,\n",
    "                                        'commentor_upvotes_total': commentor_upvotes_total,\n",
    "                                        'commentor_total_happyness': commentor_total_happyness,\n",
    "                                        'commentor_total_saltiness': commentor_total_saltiness,\n",
    "                                        'total_comments': total_comments,\n",
    "                                        'qty_salty_comments': qty_salty_comments, \n",
    "                                        'qty_non_salty_comments': qty_non_salty_comments,\n",
    "                                        'salty_comments': salty_comments, \n",
    "                                        'sweet_comments': sweet_comments} ])\n",
    "delayed_results = pd.concat((delayed_results, outputDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# How many Descendants per story? (Descending)\n",
    "\n",
    "StoriesPerUser = \"\"\"\n",
    "SELECT descendants, COUNT(*) as cnt\n",
    "FROM `bigquery-public-data.hacker_news.stories`\n",
    "GROUP BY descendants\n",
    "ORDER BY descendants DESC\n",
    "\"\"\"\n",
    "\n",
    "display(querytodf(StoriesPerUser).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bbc955d552b8031909adfd606c17f2176adf7b2"
   },
   "outputs": [],
   "source": [
    "'''%%time\n",
    "\n",
    "list_names=commentorList\n",
    "\n",
    "delayed_results = testingDF\n",
    "for x in list_names:\n",
    "\n",
    "    # Select subdf for the selected author. \n",
    "    subdf = ds2[ds2['by'].values == x]\n",
    "\n",
    "    # Generate the sentiment analysis for each of the commentor's comments. \n",
    "    subdf['comment_sentiment'] = subdf.text.apply(lambda x: get_sentiment(noURLS(noHTML(encode_decode(x)))))\n",
    "    subdf['cleaned_comment'] = subdf.text.apply(lambda x: noURLS(noHTML(encode_decode(x))))\n",
    "    subdf = subdf.sort_values(by=['comment_sentiment'],ascending=True)\n",
    "\n",
    "    # Commentor\n",
    "    commentor = x\n",
    "\n",
    "    # Create the first output, a float indicating commentor's mean sentiment score. \n",
    "    commentor_sentiment = subdf['comment_sentiment'].mean() \n",
    "\n",
    "    # Upvotes Mean\n",
    "    commentor_upvotes_mean = subdf['ranking'].mean() \n",
    "\n",
    "    # Upvotes Total\n",
    "    commentor_upvotes_total = subdf['ranking'].sum()\n",
    "\n",
    "    # Total Happiness\n",
    "    commentor_total_happyness = subdf[subdf['comment_sentiment'] > 0.0].comment_sentiment.sum() \n",
    "\n",
    "    # Total Saltiness\n",
    "    commentor_total_saltiness = subdf[subdf['comment_sentiment'] < 0.0].comment_sentiment.sum() \n",
    "\n",
    "    # Third output, total number of commments\n",
    "    total_comments = len(subdf.index)\n",
    "\n",
    "    # Total salty comments\n",
    "    qty_salty_comments = (subdf.comment_sentiment < 0.0).sum()\n",
    "\n",
    "    # Total non-salty comments\n",
    "    qty_non_salty_comments = (subdf.comment_sentiment > 0.0).sum()\n",
    "\n",
    "    # Create the second output, a list of the commentor's saltiest comments. \n",
    "    salty_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']][0:9].to_json(orient='records')\n",
    "\n",
    "    # Ten most positive comments\n",
    "    sweet_comments = subdf[['time','comment_sentiment','ranking','cleaned_comment', 'stitle']].tail(10).to_json(orient='records')\n",
    "\n",
    "    outputDF = pd.DataFrame.from_records([{ 'commentor': commentor, \n",
    "                                            'commentor_sentiment': commentor_sentiment, \n",
    "                                            'commentor_upvotes_mean': commentor_upvotes_mean,\n",
    "                                            'commentor_upvotes_total': commentor_upvotes_total,\n",
    "                                            'commentor_total_happyness': commentor_total_happyness,\n",
    "                                            'commentor_total_saltiness': commentor_total_saltiness,\n",
    "                                            'total_comments': total_comments,\n",
    "                                            'qty_salty_comments': qty_salty_comments, \n",
    "                                            'qty_non_salty_comments': qty_non_salty_comments,\n",
    "                                            'salty_comments': salty_comments, \n",
    "                                            'sweet_comments': sweet_comments} ])\n",
    "    delayed_results = pd.concat((delayed_results, outputDF))\n",
    "\n",
    "    \n",
    "results = dask.compute(delayed_results)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://myinstance.notebook.us-east-1.sagemaker.aws/notebooks/image_classify.ipynb\n",
    "And URL of accessing Dask Dashboard will be:\n",
    "\n",
    "https://myinstance.notebook.us-east-1.sagemaker.aws/proxy/8787/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_empty",
   "language": "python",
   "name": "conda_empty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
